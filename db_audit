# db_audit.py
import argparse
import sqlite3
from typing import Dict, List, Tuple

DB_PATH_DEFAULT = r"C:\codes\t5-db\syr_research_all.db"


def get_tables(cur: sqlite3.Cursor) -> List[str]:
    cur.execute(
        """
        SELECT name
        FROM sqlite_master
        WHERE type='table'
          AND name NOT LIKE 'sqlite_%'
        ORDER BY name
        """
    )
    return [r[0] for r in cur.fetchall()]


def get_table_info(cur: sqlite3.Cursor, table: str) -> List[Tuple]:
    cur.execute(f"PRAGMA table_info({table});")
    return cur.fetchall()


def get_cols_and_types(cur: sqlite3.Cursor, table: str):
    rows = get_table_info(cur, table)
    cols = [r[1] for r in rows]
    col_types = {r[1]: (r[2] or "") for r in rows}
    pk_cols = [r[1] for r in rows if int(r[5] or 0) == 1]
    return cols, col_types, pk_cols


def table_count(cur: sqlite3.Cursor, table: str) -> int:
    cur.execute(f"SELECT COUNT(*) FROM {table};")
    return int(cur.fetchone()[0])


def is_text_type(type_str: str) -> bool:
    t = (type_str or "").lower()
    if not t:
        return True
    return ("char" in t) or ("text" in t) or ("clob" in t) or ("varchar" in t)


def count_nulls(cur: sqlite3.Cursor, table: str, col: str) -> int:
    cur.execute(f"SELECT COUNT(*) FROM {table} WHERE {col} IS NULL;")
    return int(cur.fetchone()[0])


def count_empty_strings(cur: sqlite3.Cursor, table: str, col: str) -> int:
    cur.execute(f"SELECT COUNT(*) FROM {table} WHERE {col} = '';")
    return int(cur.fetchone()[0])


def sample_rows(cur: sqlite3.Cursor, table: str, cols: List[str], where_clause: str, limit: int):
    select_list = ", ".join(cols)
    cur.execute(f"SELECT {select_list} FROM {table} WHERE {where_clause} LIMIT {limit};")
    return cur.fetchall()


def print_section(title: str) -> None:
    print()
    print(title)
    print("=" * len(title))


def schema_specific_checks(cur: sqlite3.Cursor, tables: List[str], samples: int) -> None:
    if not {"papers", "works", "research_info"}.issubset(set(tables)):
        print("papers, works, research_info not all present. Skipping schema checks.")
        return

    print_section("Schema checks (papers, works, research_info)")
    cur.execute("SELECT COUNT(*) FROM works WHERE paper_id IS NULL;")
    print("works rows with paper_id NULL:", int(cur.fetchone()[0]))

    cur.execute("SELECT COUNT(*) FROM research_info WHERE paper_id IS NULL;")
    print("research_info rows with paper_id NULL:", int(cur.fetchone()[0]))

    cur.execute(
        """
        SELECT COUNT(*)
        FROM papers p
        LEFT JOIN works w ON w.paper_id = p.paper_id
        WHERE w.paper_id IS NULL
        """
    )
    print("papers with no works row:", int(cur.fetchone()[0]))

    cur.execute(
        """
        SELECT COUNT(*)
        FROM papers p
        LEFT JOIN research_info ri ON ri.paper_id = p.paper_id
        WHERE ri.paper_id IS NULL
        """
    )
    print("papers with no research_info row:", int(cur.fetchone()[0]))

    cur.execute(
        """
        SELECT COUNT(*)
        FROM works w
        LEFT JOIN papers p ON p.paper_id = w.paper_id
        WHERE p.paper_id IS NULL
        """
    )
    print("works whose paper_id not in papers:", int(cur.fetchone()[0]))

    cur.execute(
        """
        SELECT COUNT(*)
        FROM research_info ri
        LEFT JOIN papers p ON p.paper_id = ri.paper_id
        WHERE p.paper_id IS NULL
        """
    )
    print("research_info whose paper_id not in papers:", int(cur.fetchone()[0]))

    if samples <= 0:
        return

    print_section("Sample rows with missing paper_id")
    cols_w, _, _ = get_cols_and_types(cur, "works")
    show_w = [c for c in ["id", "paper_id", "file_name", "summary_status", "progress"] if c in cols_w]
    if show_w:
        rows = sample_rows(cur, "works", show_w, "paper_id IS NULL", limit=samples)
        if rows:
            print("works missing paper_id")
            for r in rows:
                print(dict(r))

    cols_ri, _, _ = get_cols_and_types(cur, "research_info")
    show_ri = [c for c in ["id", "paper_id", "researcher_name", "work_title", "doi", "publication_date"] if c in cols_ri]
    if show_ri:
        rows = sample_rows(cur, "research_info", show_ri, "paper_id IS NULL", limit=samples)
        if rows:
            print("research_info missing paper_id")
            for r in rows:
                print(dict(r))

    print_section("Blocking nulls (papers)")
    cols_p, types_p, _ = get_cols_and_types(cur, "papers")
    for c in ["title", "authors", "publication_date", "doi", "arxiv_id"]:
        if c in cols_p:
            n_null = count_nulls(cur, "papers", c)
            n_empty = 0
            if is_text_type(types_p.get(c, "")):
                try:
                    n_empty = count_empty_strings(cur, "papers", c)
                except Exception:
                    n_empty = 0
            print(f"papers.{c} missing:", n_null + n_empty)

    print_section("Recommended order")
    print("1 Ensure every works row has paper_id")
    print("2 Ensure every research_info row has paper_id")
    print("3 Run db_repair_enrich.py to copy across tables and parse full_text")
    print("4 Run topic_tag_openalex.py to tag topics and populate primary_topic and topics_json")


def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument("--db", default=DB_PATH_DEFAULT)
    ap.add_argument("--samples", type=int, default=5)
    args = ap.parse_args()

    conn = sqlite3.connect(args.db)
    conn.row_factory = sqlite3.Row
    cur = conn.cursor()

    tables = get_tables(cur)
    if not tables:
        print("No tables found")
        return

    print_section("Database")
    print(args.db)

    print_section("Table row counts")
    row_counts: Dict[str, int] = {}
    for t in tables:
        n = table_count(cur, t)
        row_counts[t] = n
        print(f"{t}: {n}")

    print_section("Null and empty string audit by table")
    overall = []
    for t in tables:
        if row_counts[t] == 0:
            print()
            print(f"{t}: 0 rows")
            continue

        cols, col_types, _ = get_cols_and_types(cur, t)
        print()
        print(t)
        for c in cols:
            n_null = count_nulls(cur, t, c)
            n_empty = 0
            if is_text_type(col_types.get(c, "")):
                try:
                    n_empty = count_empty_strings(cur, t, c)
                except Exception:
                    n_empty = 0

            if n_null > 0 or n_empty > 0:
                overall.append((t, c, n_null, n_empty, row_counts[t]))
                parts = []
                if n_null:
                    parts.append(f"null {n_null}")
                if n_empty:
                    parts.append(f"empty {n_empty}")
                print(f"  {c}: " + ", ".join(parts))

    if overall:
        print_section("Top missing columns overall")
        overall_sorted = sorted(overall, key=lambda x: (x[2] + x[3], x[0], x[1]), reverse=True)
        for t, c, n_null, n_empty, n_total in overall_sorted[:50]:
            miss = n_null + n_empty
            pct = (miss / n_total) * 100 if n_total else 0
            print(f"{t}.{c}: missing {miss}/{n_total} ({pct:.2f}%)")
    else:
        print("No null or empty values found")

    schema_specific_checks(cur, tables, samples=args.samples)
    conn.close()


if __name__ == "__main__":
    main()
